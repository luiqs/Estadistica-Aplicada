---
title: "Pruebas de hipotesis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Para fines de esta práctica utilizaremos la base de datos siguiente, carga en R: 
```{r}
hsb2 <- within(read.csv("https://stats.idre.ucla.edu/stat/data/hsb2.csv"), {
  race <- as.factor(race)
  schtyp <- as.factor(schtyp)
  prog <- as.factor(prog)
})
```

La base de datos llamada hsb2, es una base de datos de 200 observaciones (filas) y 11 variables de estudio. Representa a una muestra aleatoria a estudiantes de secundario de colegios, realizada por el centro nacional de estadisticas para la educacion (USA). 

Las variables son las siguientes:

+ id: Identificacion del alumno.
+ female: Genero del alumno (si es igual a 1 es female, si es igual a 0, es male).
+ race: Raza del alumno (african american, asian, hispanic, and white).
+ ses: Nivel socioeconomico del alumno (low, middle, y high).
+ schtyp: Tipo de escuela (private o public).
+ prog: Tipo de programa (general, academic y vocational).
+ read: Notas de lectura.
+ write: Notas de escritura.
+ math: Notas de matematica.
+ science: Notas de ciencias.
+ socst: Notas de Sociales.

Activemos el paquete de tidyverse (activa en conjunto ggplot2 y dplyr al mismo tiempo). Generalmente las pruebas de hipotesis se pueden realizar con las pruebas basicas del paquete stats de R, salvo algunas excepciones donde se detallará que paquete se necesita:

```{r}
library(tidyverse)
```

# 1. Pruebas paramétricas.

## A. Pruebas univariadas para la normalidad

### A.1. La prueba de Shapiro Wilk

Vamos a evaluar si es que la variable "notas de escritura" tiene o no una distribución normal. Para ello, utilizamos la funcion "shapiro.test()" del paquete "stats". Antes de realizar la prueba, recordar y revisar que nos dice la hipotesis nula y la hipotesis alterna para la prueba de shapiro. Establescan tambien el nivel de significancia (en este caso tomaremos 5%, como es la costumbre). Los que hara la funcion, es calcular el estadistico de la muestra obtenida y determinará el valor de p-value.

```{r}
shapiro.test(hsb2$write)
```
Obtenemos como resultado que el valor de p-valor (p-value) es menor a 0.05. Del resultado, rechazamos Ho, es decir, la variable nota de escritura no sigue una distribucion normal. Esto lo podemos complementar graficando la distribucion de las notas de escritura.

```{r}
hsb2 %>% ggplot(aes(x=write))+
  geom_density()
```

Podemos realizar el mismo ejercicio para las demas variables (cuantitativas) de los datos de la muestra "hsb2".

Para la variable notas de matematicas:

```{r}
shapiro.test(hsb2$math)
```
Aprovechamos para gráficar su distribución:
```{r}
hsb2 %>% ggplot(aes(x=math))+
  geom_density()
```

A pesar de que la gráfica es tentativamente "mas similar" a una distribucion normal, la prueba de shapiro nos casa de dudas, ya que rechazamos nuevamente Ho. 

##### Haremos la prueba una vez mas para la variable notas de ciencias:

```{r}
shapiro.test(hsb2$science)
```

```{r}
hsb2 %>% ggplot(aes(x=science))+
  geom_density()
```
Analice y exponga sus conclusiones.

##### Creamos una distribucion normal adrede para observar que pasaria. La llamaremos x:

```{r}
x <- tibble(x = rnorm(120, mean = 51, sd =18))

shapiro.test(x$x)

x %>% ggplot(aes(x=x))+
  geom_density()

```

En este caso, la prueba de shapiro Wilk nos dio un p-value por encima de 0.05, lo cual indica que aceptamos Ho, y concluimos que la variable "x" de la base de datos "x", tiene una distribucion normal. 

## B. Pruebas de homogeneidad de Varianzas

### B.1. Prueba de Levene
Para la prueba de Levene, necesitaremos un paquete especial, llamado "car", luego de instalarlo y activarlo, utilizarmoes la función "leveneTest()" del paquete:

```{r}
library(car)

leveneTest(hsb2$write, hsb2$math)
```
Al igual que la prueba de Shapiro Wilk y como en otras pruebas que veremos, concentremosnos en interpretar el p-value y utilzarlo en nuestro contrate de hipotesis. Acordemosnos que la Ho de la prueba de Levene nos dice "que la varianza de los grupos estudiados (write y math) nos son diferentes". La H1 por su parte, nos dice que " la varianza de los grupos son diferentes". El valor de p-vaue obtenido en la prueba de es 0.35, el cual es mayor nuestro nivel de significancia de 0.05 (nivel de confianza al 95%). De esto concluimos que aceptamos la hipotesis nula o rechazamos la hipotesis alterna. Es decir, que las varianzas para las dos muestras aleatorias analizadas no son diferentes. 


## C. Prueba de hipotesis con una media poblacional (mu) para una variable

### C.1. Prueba de Z (varianza conocida)
En esta ocasion, es necesario utilizar el paque "BSDA", instalarlo y activarlo. Utilizaremos la función z.test() del paquete BSDA. Acordemosnos que la estas pruebas se aplican a una sola variable. En este caso la aplicaremos al la variable, notas de escritura (write). Acordase que la prueba de Z, la utilizamos cuando conocemos la desviacion estandar poblacional (en este caso la asumiremos como 1, en el argumento "sigma.x="). De igual manera, en este ejemplo, estableceremos que la hipotesis Ho como el valor de la media muestral igual a 53 (mu= 53), 

Para este tipo de pruebas, no olvidar que tenemos que establecer nuestras hipotesis, tenemos 3 opciones, que la media muestral es igual a la poblacional, que es menor o que es mayor, esto tambien podemos delimitarlo en la formula (esto lo haremos modificando el argumento **alternative** = ("greater", "less" or "two.sided")).
```{r}
library(BSDA)
z.test(hsb2$write,sigma.x = 1, mu = 53, alternative = "two.sided")
```
Mayor información acerca de la función: <https://www.rdocumentation.org/packages/BSDA/versions/1.2.0/topics/z.test>

Del resultado, obtenemos un p-value menor a 0.05 (si no determinamos el nivel de confianza, este se asume como 95%,el nivel de confianza tambien podemos modificarlo mediante el argumento, conf.level = (valores del 0 al 1)). Del resultado podemos concluir que rechazamos Ho, es decir que la media poblacional no es igual a 53 (aceptamos la hipotesis alterna). El resultado de la funcion "z.test()", no solo nos brinda el p-valor, sino que tambien ofrence el valor de la media poblacional y los intervalos de confianza de la estimación. Aunque al rechazar la Ho, estos ya pierden su utilidad para generar conclusiones. Notese que si los intervamos de confianza hubiesen contemplado el valor 53, hubiesemos aceptado Ho. 

### C.2. Prueba t de Student (varianza desconocida)
Seguimos evaluando la variable "notas de escritura". Pero ahora utilizaremos la t de Student (no conocemos la desviacion estandar de la población). 

```{r}
t.test(hsb2$write, mu = 53, alternative = "two.sided", conf.level = 0.95)
```
Al correr la prueba t de Student (con los mismo valores que la prueba de Z anterior), podemos observar que en este caso, los intervalos de confianza se ensanchan un poco mas. Lo cual nos permite aceptar Ho, es decir, que la media muestral proviene de una poblacion con un valor de mu igual a 53 (esto se comprueba tambien con el p-value). Comparando esta prueba con la prueba Z, podemos evidenciar que la segunda tiene mayor precision en el constraste te hipotesis (sin embargo, no siempre se cuenta con el valor poblacional de la desviacion estandar).

## D. Prueba t de Student para comparar dos medias de dos variables aleatorias independientes
Dejamos de realizar pruebas parametricas para una sola variable, para dedicarnos ahora al analisis de dos variables (pertenescan a una poblacion o sean idependientes). En este caso, utilizaremos la prueba t de Student para dos poblaciones de independientes (masculina y femenina). Los casos masculinos y femeninos seran separados internamente por la funcion t.test(), establecer la relacion entre las variables "write" y "female". En este caso estamos separando los valores de "notas de escritura", en dos grupos, los que son femeninos y los que son masculinos. De estos dos grupos comparamos sus medias, mediante:

```{r}
t.test(hsb2$write ~ hsb2$female )
```


## E. Prueba t de Student para compara 2 medias poblacionales de dos muestras aleatorias relacionadas
En este caso, utilizamos la misma funcion anterior. Sin embargo, dos principales cambios se tiene que dar. 

+ Las variables de estudio ahora son dos poblaciones relacionadas. Es decir, que comparten los mismos elementos observacionales (p.ej. estas dos prueba tienen todos los alumnos del genero masculino y todas las alumnas del genero femenino). Bajo esta premisa, a la funcion original tendremos que suministrarle el argumente paired igual a verdadero (TRUE), el cual por defecto se encuentra en falso (FALSE)
+ De los explicado, ya no vamos a brindarle a la funcion una relacion entre variables (~), sino que establecemos dos variables de la data que queramos comparar.

Teniendo en cuenta lo explicad, calculamos el p-valor, mediante el siguiente codigo:
```{r}
t.test(hsb2$write, hsb2$read, paired = TRUE)
```


## F. ANOVA (Analisis de la Varianza)

### F.1 ANOVA de 1 factor
El anova se basa en la construccion de un modelo. En este sentido, este es el primer modelo del curso de estadistica aplicada que vamos a utilizar. Para crear un modelo, debemos usar una funcion especifica de ese modelo, para luego definir las variables de la ecuacion. Para crear un modelo ANOVA, utilizamos la funcion *aov()*. Esta funcion, espera que nos brinden 2 variables (para el ANOVA de un factor), la variable independiente y la dependiente. La variable independiente generalmente va a corresponder a una variable categorica (nominal, ordinal o discreta), y la variable dependiente es aquella que estamos evaluando en razon a su respuesta a la variable independiente. De esta manera, para la base de datos ** ** construimos un modelo anova, para la variable dependiente ** ** y la variable independiente ** ** de la siguiente manera:

```{r}
Modelo.ANOVA <- aov(write~race, data =hsb2)
```
Luego, para obtener los resultados de la prueba de ANOVA, solo debemos llamar al resumen (con funcion, **summary()**) del modelo que acabamos de construir: 
```{r}
summary(Modelo.ANOVA)
```

Del resultado identificaremos el p-valor y lo interpretaremos a través del contraste de hipotesis de la prueba ANOVA. .....


El diagrama de cajas (Box Plot) es tipicamente utilizado para gráficar las diferencias que una prueba de ANOVA nos brinda. Esto lo podemos realizar a través del paquete ggplot2, de la siguiente manera:

```{r}
ggplot(data = hsb2, aes(x=race, y=write))+
  geom_boxplot(fill = "pink")+
  geom_point(color = "blue")
```

### F.2 Prueba de Tukey para ANOVA de 1 factor

Del ejemplo anterior, podemos realizar una prueba de Tukey para identificar las diferencias especificas entre cada uno de los tratamientos en el estudio. Para ello realizamos la prueba de Tukey en el modelo ANOVA ya creado con la funcion *TukeyHSD()*. 

```{r}
TukeyHSD(Modelo.ANOVA)
```

Una manera practica de plotear las diferencias es:

```{r}
Prueba_tukey_C <- TukeyHSD(Modelo.ANOVA)
plot(Prueba_tukey_C, las = 1)
```

### F.2 ANOVA de 2 factores


```{r}
Modelo.ANOVA.2 <- aov(write~race+prog, data =hsb2)

summary(Modelo.ANOVA.2)

```


```{r}
ggplot(aes(y=write, x=race, fill = prog), data = hsb2)+
  geom_boxplot()+
  theme_bw()
```

